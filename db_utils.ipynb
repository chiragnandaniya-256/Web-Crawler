{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n",
        "from datetime import datetime\n",
        "from datetime import timedelta\n",
        "\n",
        "\n",
        "from pymongo import MongoClient\n",
        "from cfg import config, db_cfg\n",
        "\n",
        "\n",
        "client = MongoClient(db_cfg['host'], db_cfg['port'])\n",
        "\n",
        "\n",
        "db = client[db_cfg['db']]\n",
        "   \n",
        "def insert_root(url):\n",
        "    '''\n",
        "    This function manually inserts the root url in the database\n",
        "    '''\n",
        "    doc = {\n",
        "        'Link': url,\n",
        "        'Source Link': url,\n",
        "        'isCrawled':False,          #not crawled yet\n",
        "        'Last Crawled': \"Never\",\n",
        "        'Response Status':'' ,               \n",
        "        'Content Type' :'',             \n",
        "        'Content length': '',            \n",
        "        'File Path':\"\",\n",
        "        'Date Created': datetime.now()\n",
        "    }\n",
        "    db.linkcol.insert_one(doc)\n",
        "\n",
        "def insert_new_links(new_urls, source_url, max_url):\n",
        "    '''\n",
        "    Inserts all the new links on a page in database\n",
        "    source url is the link from which it was first extracted\n",
        "    '''\n",
        "    \n",
        "    for link in new_urls:\n",
        "        if(already_inserted(link)):\n",
        "            continue        \n",
        "        doc = {\n",
        "            'Link': link,\n",
        "            'Source Link': source_url,\n",
        "            'isCrawled':False,      ##Initially the links are not crawled\n",
        "            'Last Crawled': \"Never\",\n",
        "            'Response Status':'' ,              \n",
        "            'Content Type' :'',               \n",
        "            'Content length': '',             \n",
        "            'File Path':\"\",\n",
        "            'Date Created': datetime.now()\n",
        "        }\n",
        "        if max_url<=db.linkcol.count():\n",
        "            break\n",
        "        db.linkcol.insert_one(doc)   \n",
        "        print(link+\" inserted at \"+str(db.linkcol.count()))\n",
        "\n",
        "\n",
        "def already_inserted(link):\n",
        "    '''\n",
        "    checks if a link is already present in the database\n",
        "    '''\n",
        "    if db.linkcol.find_one({'Link':link})==None:\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def all_crawled():\n",
        "    '''\n",
        "    This function check if there are uncrawled links which are\n",
        "    1. If they are never crawled before or\n",
        "    2. if they are crawled before 24 hours\n",
        "    :return: count of all uncrawled links\n",
        "    '''\n",
        "    count=0\n",
        "    for doc in db.linkcol.find({}):\n",
        "        if doc['Last Crawled']!='Never':\n",
        "            time_diff = datetime.now()-doc['Last Crawled']\n",
        "            if time_diff.days>=config['time_diff']:\n",
        "                count=count+1\n",
        "        else:\n",
        "            count=count+1\n",
        "    return count\n",
        "\n",
        "def get_all_uncrawled():\n",
        "    uncrawled_url = set()\n",
        "    for doc in db.linkcol.find({}):\n",
        "        if doc['Last Crawled']=='Never':\n",
        "            uncrawled_url.add(doc['Link'])\n",
        "        else:\n",
        "            time_diff = datetime.now()-doc['Last Crawled']\n",
        "            if time_diff.days>=config['time_diff']:\n",
        "                uncrawled_url.add(doc['Link'])\n",
        "    return uncrawled_url \n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}